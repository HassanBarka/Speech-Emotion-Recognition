{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4dcf9d9-1793-4cf4-a378-7cb20206d09e",
   "metadata": {},
   "source": [
    "### Importation des Bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "898d9cfb-2b11-45b5-a8f0-ea534ea54fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-23 23:21:01.455689: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-23 23:21:06.227165: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64:/usr/local/cuda-11.8/lib64:/usr/local/cuda-11.8/lib64:/usr/local/cuda-11.8/lib64:/home/hassouni/miniconda3/envs/tf/lib/\n",
      "2024-03-23 23:21:06.227397: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64:/usr/local/cuda-11.8/lib64:/usr/local/cuda-11.8/lib64:/usr/local/cuda-11.8/lib64:/home/hassouni/miniconda3/envs/tf/lib/\n",
      "2024-03-23 23:21:06.227425: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import wave\n",
    "import wavio\n",
    "import joblib\n",
    "import librosa\n",
    "import pyaudio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import sounddevice as sd\n",
    "from pydub import AudioSegment\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55180105-32b4-423d-9f32-04204d00c453",
   "metadata": {},
   "source": [
    "### Importation des Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9ff77854-2833-425d-9433-1e74cf680ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = load_model('model_all95.h5')\n",
    "encoder = joblib.load('encoder_all.pkl')\n",
    "scaler = joblib.load('scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a78a3e-f597-471a-a871-0edbd58075ae",
   "metadata": {},
   "source": [
    "### Features Extractions Fuctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ab130963-a9dc-46a1-81ab-f271c9848373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zcr(data, frame_length=2048, hop_length=512):\n",
    "    zcr = librosa.feature.zero_crossing_rate(y=data, frame_length=frame_length, hop_length=hop_length)\n",
    "    return np.squeeze(zcr)\n",
    "\n",
    "def rmse(data, frame_length=2048, hop_length=512):\n",
    "    rmse = librosa.feature.rms(y=data, frame_length=frame_length, hop_length=hop_length)\n",
    "    return np.squeeze(rmse)\n",
    "    \n",
    "def mfcc(data, sr, frame_length=2048, hop_length=512, flatten: bool = True):\n",
    "    mfcc_feature = librosa.feature.mfcc(y=data, sr=sr)\n",
    "    return np.squeeze(mfcc_feature.T) if not flatten else np.ravel(mfcc_feature.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "395f8a1e-2e44-491c-b747-8e74b51d7242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(data, sr, frame_length=2048, hop_length=512):\n",
    "    result = np.array([])\n",
    "    result = np.hstack((result,\n",
    "                        zcr(data, frame_length, hop_length),\n",
    "                        rmse(data, frame_length, hop_length),\n",
    "                        mfcc(data, sr, frame_length, hop_length)\n",
    "                      ))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9507e976-7165-4701-9073-7b44c9fe8eaf",
   "metadata": {},
   "source": [
    "### Preduction fonction from path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "13875c9d-0981-4ab2-bf92-e68f47e2f57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_emotion(data,sample_rate):\n",
    "    if len(data) < 55125 and len(data)> 50000:\n",
    "        data = np.pad(data, (0, 55125 - len(data)), mode='constant')\n",
    "    data = extract_features(data,sample_rate)\n",
    "    data = scaler.transform(data.reshape(1, -1))\n",
    "    pred = model.predict(data)\n",
    "    return encoder.inverse_transform(pred)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b5c59778-c193-41c6-a227-fb72d3c8b04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(path):\n",
    "    audio_duration = get_audio_duration(path)\n",
    "    if audio_duration > 4:\n",
    "        segments = segment_recording(path)\n",
    "        predicts = []\n",
    "        for segment in segments:\n",
    "            predicts.append(predict_emotion(segment[0],segment[1]))\n",
    "        return predicts\n",
    "    else:\n",
    "        data, sample_rate = librosa.load(path, duration=2.5, offset=0.6)\n",
    "        return predict_emotion(data,sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4decde70-93fc-44b4-b591-e5810c710502",
   "metadata": {},
   "source": [
    "### Audio recording Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "06cf3e1b-65a1-471a-a52c-58adb288b5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_audio(file_path, duration=4, sample_rate=22050):\n",
    "    \"\"\"\n",
    "    Record audio from the microphone and save it to a WAV file.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): The path to the WAV file to save.\n",
    "    - duration (float): The duration of the recording in seconds (default 4.0 seconds).\n",
    "    - sample_rate (int): The sampling rate in Hz (default 22050 Hz).\n",
    "    \"\"\"\n",
    "    print(\"Start speaking...\")\n",
    "    # Calculate the number of frames based on the duration and sample rate\n",
    "    num_frames = int(duration * sample_rate)\n",
    "    # Record audio with floating point data type\n",
    "    audio_data = sd.rec(frames=num_frames, samplerate=sample_rate, channels=1, dtype='float32')\n",
    "    sd.wait()\n",
    "    print(\"Recording finished.\")\n",
    "\n",
    "    # Save the recorded audio to a WAV file\n",
    "    wavio.write(file_path, audio_data, sample_rate, sampwidth=4)  # sampwidth=4 for float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4b71360e-6735-4919-b06e-938db360c0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_duration(file_path):\n",
    "    # Open the audio file\n",
    "    with sf.SoundFile(file_path, 'r') as f:\n",
    "        # Get the number of frames and the sampling frequency\n",
    "        num_frames = len(f)\n",
    "        samplerate = f.samplerate\n",
    "        # Calculate the duration in seconds\n",
    "        duration = num_frames / samplerate\n",
    "    return duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d44b4a59-a96b-4254-a87d-06e29a396a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_recording(path):\n",
    "    # Charger le fichier audio\n",
    "    audio = AudioSegment.from_file(path)\n",
    "    \n",
    "    # Durée d'un segment en millisecondes ( secondes)\n",
    "    segment_duration = 3500\n",
    "    \n",
    "    # Diviser l'audio en segments de 5 secondes\n",
    "    segments = []\n",
    "    for start_time in range(0, len(audio), segment_duration):\n",
    "        end_time = start_time + segment_duration\n",
    "        segment = audio[start_time:end_time]\n",
    "        segments.append(segment)\n",
    "    file_names = []\n",
    "    for i, segment in enumerate(segments):\n",
    "        file_names.append(segment.export(f\"segment_{i+1}.wav\", format=\"wav\"))\n",
    "    audios = []\n",
    "    for file in file_names:\n",
    "        if get_audio_duration(file) > 2.5:\n",
    "            audios.append(librosa.load(file.name,duration=2.5, offset=0.6))\n",
    "        \n",
    "    return audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cdca38f4-0298-419f-a37a-bf9da01eb0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start speaking...\n",
      "Recording finished.\n"
     ]
    }
   ],
   "source": [
    "output_file = \"recorded_audio.wav\"\n",
    "record_audio(output_file, duration=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a4d3f101-b9e0-492a-b945-85168668bd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hassouni/miniconda3/envs/tf/lib/python3.9/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 109ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'angry'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(\"recorded_audio.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c9ce0b35-4c8b-44cb-be76-90be2f66c760",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hassouni/miniconda3/envs/tf/lib/python3.9/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 97ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'disgust'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction('/home/hassouni/PFA/model/Ravdess/Actor_04/03-01-07-01-01-01-04.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "108ca1d9-5006-47b3-8f32-e13f00599084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "def record_audio(file_path, duration=4, sample_rate=22050, chunk_size=2048, format=pyaudio.paInt16, channels=1):\n",
    "    \"\"\"\n",
    "    Record audio from the microphone and save it to a WAV file.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): The path to the WAV file to save.\n",
    "    - duration (float): The duration of the recording in seconds (default 4.0 seconds).\n",
    "    - sample_rate (int): The sampling rate in Hz (default 44100 Hz).\n",
    "    - chunk_size (int): The size of audio chunks to read at a time (default 1024).\n",
    "    - format: The format of the audio data (default pyaudio.paInt16).\n",
    "    - channels: The number of audio channels (default 1).\n",
    "    \"\"\"\n",
    "    audio = pyaudio.PyAudio()\n",
    "\n",
    "    # Open stream\n",
    "    stream = audio.open(format=format,\n",
    "                        channels=channels,\n",
    "                        rate=sample_rate,\n",
    "                        input=True,\n",
    "                        frames_per_buffer=chunk_size)\n",
    "\n",
    "    print(\"Recording...\")\n",
    "    frames = []\n",
    "\n",
    "    # Record audio\n",
    "    for i in range(0, int(sample_rate / chunk_size * duration)):\n",
    "        data = stream.read(chunk_size)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"Recording finished.\")\n",
    "\n",
    "    # Stop and close the stream\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "    # Save the recorded audio to a WAV file\n",
    "    with wave.open(file_path, 'wb') as wf:\n",
    "        wf.setnchannels(channels)\n",
    "        wf.setsampwidth(audio.get_sample_size(format))\n",
    "        wf.setframerate(sample_rate)\n",
    "        wf.writeframes(b''.join(frames))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "edb8addd-bfbf-4c04-a431-53b94ad5b2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording finished.\n"
     ]
    }
   ],
   "source": [
    "record_audio(\"recorded_audio1.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d72f8be8-8b37-49a3-b2e7-5cf1aa6fbdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hassouni/miniconda3/envs/tf/lib/python3.9/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 108ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'angry'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(\"recorded_audio1.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794471ca-7062-4116-ba20-7216fec5cdfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
